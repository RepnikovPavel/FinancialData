{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dateutil.relativedelta import *\n",
    "from dateutil.easter import *\n",
    "from dateutil.rrule import *\n",
    "from dateutil.parser import *\n",
    "from datetime import *\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import conf\n",
    "from UI.LOG import *\n",
    "import cv2\n",
    "from aml.train_pipeline import *  \n",
    "from aml.train_pipeline import *\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor,FasterRCNN_ResNet50_FPN_Weights\n",
    "from torchinfo import summary\n",
    "\n",
    "# from torchvision.models.detection import ssd300_vgg16,SSD300_VGG16_Weights\n",
    "from torchvision.models.detection.ssd import SSDClassificationHead,SSD300_VGG16_Weights,det_utils\n",
    "from torchvision.models.detection import ssd300_vgg16\n",
    "\n",
    "import torch\n",
    "\n",
    "import aml.model_using as model_using\n",
    "import aml.support_func as support_funcS\n",
    "import aml.time_mesuarment as time_mesuarment\n",
    "import sys\n",
    "\n",
    "import aml.managers as managers\n",
    "import aml.img_processing as img_processing\n",
    "import random\n",
    "import numpy as np\n",
    "import pprint\n",
    "from torchinfo import summary\n",
    "from aml.img_processing import *\n",
    "\n",
    "from PIL import Image\n",
    "import aml.models as models\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint as Print\n",
    "from PIL import Image\n",
    "import warnings\n",
    "from torchvision.utils import draw_bounding_boxes  \n",
    "from torchvision.io.image import read_image\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "from torchvision.ops import nms \n",
    "from torchmetrics.detection.mean_ap import MeanAveragePrecision as mAP\n",
    "from matplotlib.transforms import Affine2D\n",
    "import mpl_toolkits.axisartist.floating_axes as floating_axes\n",
    "from IPython.display import IFrame, display, HTML\n",
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostClassifier\n",
    "from data_manip import label_encode_feautures_\n",
    "import catboost\n",
    "from io import StringIO \n",
    "import sys\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from catboost import utils\n",
    "from sklearn import metrics\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from tqdm import tqdm\n",
    "import lightgbm as lgb\n",
    "tqdm.pandas()\n",
    "\n",
    "def simple_plot(x,y,title=''):\n",
    "    fig, ax = plt.subplots()\n",
    "    fig.set_size_inches(16,9)\n",
    "    ax.plot(x,y)\n",
    "    ax.set_title(title)\n",
    "    return fig,ax\n",
    "def Gini(fpr,tpr):\n",
    "    return 2*metrics.auc(fpr,tpr)-1\n",
    "def plot_gxb_train_results(results):\n",
    "    fig, ax = plt.subplots()\n",
    "    fig.set_size_inches(16,9)\n",
    "    ax.plot(results['train-auc-mean'],label= 'train-auc-mean')\n",
    "    ax.plot(results['test-auc-mean'],label= 'test-auc-mean')\n",
    "    ax.legend()\n",
    "    return fig,ax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv(conf.X_train_dataset,index_col=False)\n",
    "Y = pd.read_csv(conf.Y_train_dataset,index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1199861, 565)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['zip_code']\n"
     ]
    }
   ],
   "source": [
    "X_train, X_validation, y_train, y_validation = train_test_split(X, Y, train_size=0.8, random_state=1234)\n",
    "features_names = [el for el in X]\n",
    "cat_features = np.setdiff1d(label_encode_feautures_,np.setdiff1d(label_encode_feautures_,features_names))\n",
    "print(cat_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'learning_rate': 0.01,\n",
    "    'max_depth': -1,\n",
    "    'boosting_type': 'gbdt',\n",
    "    'n_estimators': 4000,\n",
    "    'scale_pos_weight': np.sum(np.where(Y==0))/np.sum(np.where(Y==1)),\n",
    "    'objective':'binary',\n",
    "    'n_jobs':8,\n",
    "    'seed':0,\n",
    "    'subsample': 0.9,\n",
    "}    \n",
    "model = lgb.LGBMClassifier(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/python3venvs/ml/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "\n",
      "/home/user/python3venvs/ml/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 231608, number of negative: 968253\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.099861 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4042\n",
      "[LightGBM] [Info] Number of data points in the train set: 1199861, number of used features: 506\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.193029 -> initscore=-1.430447\n",
      "[LightGBM] [Info] Start training from score -1.430447\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(learning_rate=0.01, n_estimators=4000, n_jobs=8,\n",
       "               objective=&#x27;binary&#x27;, scale_pos_weight=4.172730101649272, seed=0,\n",
       "               subsample=0.9)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(learning_rate=0.01, n_estimators=4000, n_jobs=8,\n",
       "               objective=&#x27;binary&#x27;, scale_pos_weight=4.172730101649272, seed=0,\n",
       "               subsample=0.9)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier(learning_rate=0.01, n_estimators=4000, n_jobs=8,\n",
       "               objective='binary', scale_pos_weight=4.172730101649272, seed=0,\n",
       "               subsample=0.9)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC 0.7468432725874995\n",
      "Gini 0.493686545174999\n"
     ]
    }
   ],
   "source": [
    "preds_ = model.predict(X_validation)\n",
    "probas_ = model.predict_proba(X_validation)\n",
    "fpr,tpr,tr = metrics.roc_curve(y_validation,probas_[:,1],pos_label=1)\n",
    "print('AUC {}'.format(metrics.auc(fpr,tpr)))\n",
    "print('Gini {}'.format(Gini(fpr,tpr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(590977, 563)\n"
     ]
    }
   ],
   "source": [
    "X_eval = pd.read_csv(conf.X_test_dataset,index_col=False)\n",
    "print(X_eval.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['emp_length_and_home_ownership_38' 'emp_length_and_home_ownership_50'\n",
      " 'purpose_and_home_ownership_33' 'purpose_and_home_ownership_51'\n",
      " 'purpose_and_home_ownership_81']\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['emp_length_and_home_ownership_38', 'emp_length_and_home_ownership_50', 'purpose_and_home_ownership_33', 'purpose_and_home_ownership_51', 'purpose_and_home_ownership_81'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m names_diff \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msetdiff1d(ns1,ns2)\n\u001b[1;32m      4\u001b[0m \u001b[39mprint\u001b[39m(names_diff)\n\u001b[0;32m----> 5\u001b[0m X_eval\u001b[39m.\u001b[39;49mdrop(columns\u001b[39m=\u001b[39;49mnames_diff,inplace\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/python3venvs/ml/lib/python3.10/site-packages/pandas/core/frame.py:5266\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   5118\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdrop\u001b[39m(\n\u001b[1;32m   5119\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   5120\u001b[0m     labels: IndexLabel \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5127\u001b[0m     errors: IgnoreRaise \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   5128\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   5129\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   5130\u001b[0m \u001b[39m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[1;32m   5131\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5264\u001b[0m \u001b[39m            weight  1.0     0.8\u001b[39;00m\n\u001b[1;32m   5265\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5266\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mdrop(\n\u001b[1;32m   5267\u001b[0m         labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[1;32m   5268\u001b[0m         axis\u001b[39m=\u001b[39;49maxis,\n\u001b[1;32m   5269\u001b[0m         index\u001b[39m=\u001b[39;49mindex,\n\u001b[1;32m   5270\u001b[0m         columns\u001b[39m=\u001b[39;49mcolumns,\n\u001b[1;32m   5271\u001b[0m         level\u001b[39m=\u001b[39;49mlevel,\n\u001b[1;32m   5272\u001b[0m         inplace\u001b[39m=\u001b[39;49minplace,\n\u001b[1;32m   5273\u001b[0m         errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m   5274\u001b[0m     )\n",
      "File \u001b[0;32m~/python3venvs/ml/lib/python3.10/site-packages/pandas/core/generic.py:4549\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4547\u001b[0m \u001b[39mfor\u001b[39;00m axis, labels \u001b[39min\u001b[39;00m axes\u001b[39m.\u001b[39mitems():\n\u001b[1;32m   4548\u001b[0m     \u001b[39mif\u001b[39;00m labels \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 4549\u001b[0m         obj \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39;49m_drop_axis(labels, axis, level\u001b[39m=\u001b[39;49mlevel, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[1;32m   4551\u001b[0m \u001b[39mif\u001b[39;00m inplace:\n\u001b[1;32m   4552\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[0;32m~/python3venvs/ml/lib/python3.10/site-packages/pandas/core/generic.py:4591\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[0;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[1;32m   4589\u001b[0m         new_axis \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39mdrop(labels, level\u001b[39m=\u001b[39mlevel, errors\u001b[39m=\u001b[39merrors)\n\u001b[1;32m   4590\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 4591\u001b[0m         new_axis \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39;49mdrop(labels, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[1;32m   4592\u001b[0m     indexer \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39mget_indexer(new_axis)\n\u001b[1;32m   4594\u001b[0m \u001b[39m# Case for non-unique axis\u001b[39;00m\n\u001b[1;32m   4595\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/python3venvs/ml/lib/python3.10/site-packages/pandas/core/indexes/base.py:6696\u001b[0m, in \u001b[0;36mIndex.drop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   6694\u001b[0m \u001b[39mif\u001b[39;00m mask\u001b[39m.\u001b[39many():\n\u001b[1;32m   6695\u001b[0m     \u001b[39mif\u001b[39;00m errors \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m-> 6696\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlist\u001b[39m(labels[mask])\u001b[39m}\u001b[39;00m\u001b[39m not found in axis\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   6697\u001b[0m     indexer \u001b[39m=\u001b[39m indexer[\u001b[39m~\u001b[39mmask]\n\u001b[1;32m   6698\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdelete(indexer)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['emp_length_and_home_ownership_38', 'emp_length_and_home_ownership_50', 'purpose_and_home_ownership_33', 'purpose_and_home_ownership_51', 'purpose_and_home_ownership_81'] not found in axis\""
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "ns1 = [el for el in X]\n",
    "ns2 = [el for el in X_eval]\n",
    "names_diff1 = np.setdiff1d(ns1,ns2)\n",
    "names_diff2=  np.setdiff1d(ns2,ns1)\n",
    "print(names_diff2)\n",
    "# X_eval.drop(columns=names_diff,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Number of features of the model must match the input. Model n_features_ is 565 and input n_features is 563",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m     os\u001b[39m.\u001b[39msystem(\u001b[39m'\u001b[39m\u001b[39mzip \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(submission_zip, submission_csv))\n\u001b[1;32m      9\u001b[0m X_eval \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(conf\u001b[39m.\u001b[39mX_test_dataset,index_col\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m---> 10\u001b[0m eval_preds_ \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict(X_eval)\n\u001b[1;32m     11\u001b[0m eval_proba_ \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict_proba(X_eval)\n\u001b[1;32m     12\u001b[0m probability_of_positive_class \u001b[39m=\u001b[39m eval_proba_[:,\u001b[39m1\u001b[39m]\n",
      "File \u001b[0;32m~/python3venvs/ml/lib/python3.10/site-packages/lightgbm/sklearn.py:1178\u001b[0m, in \u001b[0;36mLGBMClassifier.predict\u001b[0;34m(self, X, raw_score, start_iteration, num_iteration, pred_leaf, pred_contrib, validate_features, **kwargs)\u001b[0m\n\u001b[1;32m   1166\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\n\u001b[1;32m   1167\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   1168\u001b[0m     X: _LGBM_ScikitMatrixLike,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1175\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any\n\u001b[1;32m   1176\u001b[0m ):\n\u001b[1;32m   1177\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Docstring is inherited from the LGBMModel.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1178\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict_proba(\n\u001b[1;32m   1179\u001b[0m         X\u001b[39m=\u001b[39;49mX,\n\u001b[1;32m   1180\u001b[0m         raw_score\u001b[39m=\u001b[39;49mraw_score,\n\u001b[1;32m   1181\u001b[0m         start_iteration\u001b[39m=\u001b[39;49mstart_iteration,\n\u001b[1;32m   1182\u001b[0m         num_iteration\u001b[39m=\u001b[39;49mnum_iteration,\n\u001b[1;32m   1183\u001b[0m         pred_leaf\u001b[39m=\u001b[39;49mpred_leaf,\n\u001b[1;32m   1184\u001b[0m         pred_contrib\u001b[39m=\u001b[39;49mpred_contrib,\n\u001b[1;32m   1185\u001b[0m         validate_features\u001b[39m=\u001b[39;49mvalidate_features,\n\u001b[1;32m   1186\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m   1187\u001b[0m     )\n\u001b[1;32m   1188\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mcallable\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_objective) \u001b[39mor\u001b[39;00m raw_score \u001b[39mor\u001b[39;00m pred_leaf \u001b[39mor\u001b[39;00m pred_contrib:\n\u001b[1;32m   1189\u001b[0m         \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/python3venvs/ml/lib/python3.10/site-packages/lightgbm/sklearn.py:1208\u001b[0m, in \u001b[0;36mLGBMClassifier.predict_proba\u001b[0;34m(self, X, raw_score, start_iteration, num_iteration, pred_leaf, pred_contrib, validate_features, **kwargs)\u001b[0m\n\u001b[1;32m   1196\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict_proba\u001b[39m(\n\u001b[1;32m   1197\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   1198\u001b[0m     X: _LGBM_ScikitMatrixLike,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1205\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any\n\u001b[1;32m   1206\u001b[0m ):\n\u001b[1;32m   1207\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Docstring is set after definition, using a template.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1208\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mpredict(\n\u001b[1;32m   1209\u001b[0m         X\u001b[39m=\u001b[39;49mX,\n\u001b[1;32m   1210\u001b[0m         raw_score\u001b[39m=\u001b[39;49mraw_score,\n\u001b[1;32m   1211\u001b[0m         start_iteration\u001b[39m=\u001b[39;49mstart_iteration,\n\u001b[1;32m   1212\u001b[0m         num_iteration\u001b[39m=\u001b[39;49mnum_iteration,\n\u001b[1;32m   1213\u001b[0m         pred_leaf\u001b[39m=\u001b[39;49mpred_leaf,\n\u001b[1;32m   1214\u001b[0m         pred_contrib\u001b[39m=\u001b[39;49mpred_contrib,\n\u001b[1;32m   1215\u001b[0m         validate_features\u001b[39m=\u001b[39;49mvalidate_features,\n\u001b[1;32m   1216\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m   1217\u001b[0m     )\n\u001b[1;32m   1218\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mcallable\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_objective) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m (raw_score \u001b[39mor\u001b[39;00m pred_leaf \u001b[39mor\u001b[39;00m pred_contrib):\n\u001b[1;32m   1219\u001b[0m         _log_warning(\u001b[39m\"\u001b[39m\u001b[39mCannot compute class probabilities or labels \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1220\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39mdue to the usage of customized objective function.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1221\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39mReturning raw scores instead.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/python3venvs/ml/lib/python3.10/site-packages/lightgbm/sklearn.py:894\u001b[0m, in \u001b[0;36mLGBMModel.predict\u001b[0;34m(self, X, raw_score, start_iteration, num_iteration, pred_leaf, pred_contrib, validate_features, **kwargs)\u001b[0m\n\u001b[1;32m    892\u001b[0m n_features \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n\u001b[1;32m    893\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_features \u001b[39m!=\u001b[39m n_features:\n\u001b[0;32m--> 894\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNumber of features of the model must \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    895\u001b[0m                      \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmatch the input. Model n_features_ is \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_features\u001b[39m}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    896\u001b[0m                      \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39minput n_features is \u001b[39m\u001b[39m{\u001b[39;00mn_features\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    897\u001b[0m \u001b[39m# retrive original params that possibly can be used in both training and prediction\u001b[39;00m\n\u001b[1;32m    898\u001b[0m \u001b[39m# and then overwrite them (considering aliases) with params that were passed directly in prediction\u001b[39;00m\n\u001b[1;32m    899\u001b[0m predict_params \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_params(stage\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpredict\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Number of features of the model must match the input. Model n_features_ is 565 and input n_features is 563"
     ]
    }
   ],
   "source": [
    "def make_submission(positive_probabilities):\n",
    "    d = {'index': [i for i in range(0,len(positive_probabilities))], 'loan_status': positive_probabilities}\n",
    "    o_df = pd.DataFrame(data=d)\n",
    "    submission_csv = os.path.join('answer.csv')\n",
    "    submission_zip = os.path.join(conf.data_folder,'answer.zip')\n",
    "    o_df.to_csv(submission_csv,index=False)\n",
    "    os.system('rm {}'.format(submission_zip))\n",
    "    os.system('zip {} {}'.format(submission_zip, submission_csv))\n",
    "eval_preds_ = model.predict(X_eval)\n",
    "eval_proba_ = model.predict_proba(X_eval)\n",
    "probability_of_positive_class = eval_proba_[:,1]\n",
    "probability_of_negative_class = eval_proba_[:,0]\n",
    "make_submission(positive_probabilities=probability_of_positive_class)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
